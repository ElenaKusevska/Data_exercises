{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from guided project on Coursera: Simulating Time Series Data by Parallel Computing in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - define a rate calculation function\n",
    "def find_rate(data=None):\n",
    "    \n",
    "    if data is None:\n",
    "      print(\"Error. Please pass time-dependent data.\")\n",
    "      return None\n",
    "    try:\n",
    "      # fill in here\n",
    "      index = data.iloc[:,0].values.astype(np.i64)//10**9 # floor division\n",
    "      data['index_col'] = index\n",
    "    \n",
    "      values = pd.Series(data.iloc[:,1].values, index=index)\n",
    "      rate = values.diff()/(data['index_col'].diff().values)\n",
    "      data['rate'] = rate.values\n",
    "        \n",
    "      data.fillna(0, inplace=True)\n",
    "      data['rate'] = data['rate'].round(5)\n",
    "      \n",
    "    except AttributeError as error:\n",
    "      print(\"Attribute error:\" + error)\n",
    "    except:\n",
    "      print(\"Unexpected error:\" + sys.exc_info()[0])\n",
    "      raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Calculate rate of time-dependent parameters. If restarting the script, ensure Runtime is set to \"TPU\". Go to Runtime -> Change runtime type -> Select TPU.\n",
    "FILENAMES = [\"paramX1wrtTime.csv\",\n",
    "             \"paramX2wrtTime.csv\", # additional data file (add your own)\n",
    "             ]\n",
    "\n",
    "for file in FILENAMES:\n",
    "    # split the file path to get the parameter name\n",
    "    name = file.split('wrt')\n",
    "\n",
    "    # print parameter name\n",
    "    print(name[0])\n",
    "\n",
    "    # get full file path\n",
    "    filepath = path.join(\"./\", file)\n",
    "\n",
    "    # open the file\n",
    "    data_file = pd.read_csv(filepath, header=0, index_col=False)\n",
    "\n",
    "    # fill in here\n",
    "    print(data_file.dtypes)\n",
    "    data_file.iloc[:,0] = pd.to_datetime(data_file.iloc[:,0])\n",
    "    print(\"-----\")\n",
    "    print(data_file.dtypes)\n",
    "    find_rate(data_file)\n",
    "    print(data_file.head(5))\n",
    "    data_file.drop(data_file.columns[[0,2]], axis=1, inplace=True) # drop two columns\n",
    "                                                                  # becayuse inplace=True\n",
    "                                                                  # after every column\n",
    "                                                                  # index updates after every column deletion\n",
    "                                                                  # so, with index = 0 and 2, we delete\n",
    "                                                                  # the first and fourth column\n",
    "    out_path = path.join(path.join(\"./\"), name[0] + \"_rate.csv\")\n",
    "    data_file.to_csv(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiprocessing_time_series_example.ipynb\r\n",
      "original.csv\r\n",
      "parallel_code_empty.ipynb\r\n",
      "paramX2wrtTime.csv\r\n",
      "xampp-linux-x64-7.4.8-0-installer.run\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Generate rate samples for each column. If restarting the script, ensure Runtime is set to \"TPU\". Go to Runtime -> Change runtime type -> Select TPU.\n",
    "\n",
    "# utilize the original calculated rates to simulate or generate new rate values. Use these rate values\n",
    "# to simulate real world samples. The new rate values will follow the same distribution as the original ones.\n",
    "\n",
    "filenames = [\"paramX1_rate.csv\",\n",
    "             \"paramX2_rate.csv\", # add more files here\n",
    "            ] \n",
    "\n",
    "# initialise variables\n",
    "random_rate = []\n",
    "samples = 10000 # number of rate samples required\n",
    "rate_df = pd.DataFrame()\n",
    "pool = Pool(processes=1) # define number of parallel processes required\n",
    "\n",
    "# Generate time series\n",
    "for file in filenames:\n",
    "\n",
    "    # split filename to get parameter name\n",
    "    name = file.split('_')\n",
    "\n",
    "    # print parameter name\n",
    "    print(name[0])\n",
    "\n",
    "    # get full file path\n",
    "    filepath = path.join(\"./\", file)\n",
    "\n",
    "    # read file\n",
    "    data_file = pd.read_csv(filepath, header=0, index_col=False)\n",
    "\n",
    "    # convert first column to 'datetimens' datatype\n",
    "    data_file.iloc[:, 0] = pd.to_datetime(data_file.iloc[:, 0])\n",
    "\n",
    "    # store 'rate' column as 'data'\n",
    "    data = data_file['rate']\n",
    "\n",
    "    # get random samples\n",
    "    values = np.random.rand(samples)\n",
    "\n",
    "    # fill in here\n",
    "    x_grid = pool.starmap(np.linspace, ((min(data), mac(data), samples), )\n",
    "    kde = pool.starmap(gaussian_kde, ((data, \"scott\"), )) # evaluate probability of kde at each point in x_grid\n",
    "    kdepdf = kde[0].evaluate(x_grid[0])\n",
    "    #get the cumulative sum of the probability densities and divide by the total density\n",
    "    cdf = np.cumsum(kdepdf)\n",
    "    cdf = cdf/cdf[-1]\n",
    "\n",
    "    # find the indices in cdf where elements of values should be inserted to maintain\n",
    "    # the order of the cdf, hence maintaining the distribution. (The values object contains 10 000\n",
    "    # random samples)\n",
    "\n",
    "    value_bins = pool.starmap(np.searchsorted, ((cdf, values), ))\n",
    "\n",
    "    # pick the values of indices in x_grid, and store them in a random rate object.\n",
    "    random_rate = x_grid[0][tuple(value_bins)]\n",
    "\n",
    "    # convert random_rate to an array, transpose it, and convert it to a list, before storing it as\n",
    "    # a dataframe\n",
    "    tempd_df = pd.DataFrame(np.asarray(random_rate).T.tolist(), columns=[name[0]])\n",
    "    rate_df = rate_df.join(temp_df, how='outer')\n",
    "    \n",
    "\n",
    "pool.terminate() # stop all parallel processes\n",
    "\n",
    "# write 'rate_df' to file\n",
    "rate_df.to_csv(\"simulated_rate.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4+5 - If restarting the script, ensure Runtime is set to \"TPU\". Go to Runtime -> Change runtime type -> Select TPU.\n",
    "def simulate_corr(temp):\n",
    "    \"\"\"\n",
    "    Simulate original dataset, using rates and correlation. Pick a random\n",
    "    column (X), simulate other column values based on rate of change of X and\n",
    "    correlation between X and other columns. Repeat for samples count.\n",
    "    \"\"\"\n",
    "    global sdev, rate, orig_df, freq, samples\n",
    "    \n",
    "    data = orig_df\n",
    "    colRange = len(data.columns) # number of columns\n",
    "    start_vals = data.mean() # get mean\n",
    "    data_corr = data.corr() # get correlation between all columns\n",
    "    colms = data.columns.values.tolist() # list of columns\n",
    "    temp_df = pd.DataFrame(columns=colms) # empty df intialised with columns\n",
    "\n",
    "    # fill in here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 - If restarting the script, ensure Runtime is set to \"TPU\". Go to Runtime -> Change runtime type -> Select TPU.\n",
    "rate = pd.read_csv(\"./simulated_rate.csv\", header=0, index_col=False)\n",
    "print(\"Read rate file\\n\")\n",
    "concat_df, backup_df = pd.DataFrame(), pd.DataFrame()\n",
    "orig_df = pd.read_csv(\"./original.csv\", index_col=False)\n",
    "print(\"Read original df\\n\")\n",
    "\n",
    "# fill in here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
